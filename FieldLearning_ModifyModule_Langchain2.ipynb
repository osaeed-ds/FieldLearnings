{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osaeed-ds/FieldLearnings/blob/main/FieldLearning_ModifyModule_Langchain2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Field Learning - Langchain - Modify Module**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pvPcHxhErXbg"
      },
      "id": "pvPcHxhErXbg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLHkt-bMq4up"
      },
      "source": [
        "## **Introduction**\n",
        "\n",
        "In this exercise we are going to utilize modify a Langchain module.\n",
        "\n",
        "In particular we are going to modify the Cassandra class.  \n",
        "\n",
        "Currently Cassandra.from_documents does not have support for supplying the IDs for the rows, so row ids are auto generated UUIDs.  You may have a scenario where you have a meaningful primary key and you want to use that as the key in the underlying Cassandra table.  The downstream meethod, Cassandra.add_texts, does support supplying an optional list of IDs.  In this exercise, we modify Cassandra.from_documents to accept an optional list of ids.\n"
      ],
      "id": "oLHkt-bMq4up"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUeV_S5q4u0"
      },
      "source": [
        "## **Prerequisites Setup**\n"
      ],
      "id": "WQUeV_S5q4u0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1p8iUgjq4u2"
      },
      "source": [
        "* Follow [these steps](https://docs.datastax.com/en/astra-serverless/docs/vector-search/overview.html) to create a new vector search enabled database in Astra.\n",
        "* Generate a new [\"Database Administrator\" token](https://docs.datastax.com/en/astra-serverless/docs/manage/org/manage-tokens.html)\n",
        "* Download the secure connect bundle for the database you just created (you can do this from the \"Connect\" tab of your database.\n",
        "* You will also need the necessary secret for the LLM provider of your choice:\n",
        " - If Open AI, then you will need an [Open AI API Key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key). This will require an Open AI account with billing enabled\n",
        " - If Vertex AI, you will need a config file\n",
        " - For more details, see [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org.\n"
      ],
      "id": "Z1p8iUgjq4u2"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2953d95b",
      "metadata": {
        "id": "2953d95b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2338c15e-274a-4e92-a189-701f8107112e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.35.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.315)\n",
            "Requirement already satisfied: cassio in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.10.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.10.4)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.21)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.44)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: cassandra-driver>=3.28.0 in /usr/local/lib/python3.10/dist-packages (from cassio) (3.28.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0->cassio) (1.16.0)\n",
            "Requirement already satisfied: geomet<0.3,>=0.1 in /usr/local/lib/python3.10/dist-packages (from cassandra-driver>=3.28.0->cassio) (0.2.1.post1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.17.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.59.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.6.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver>=3.28.0->cassio) (8.1.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.5.0)\n"
          ]
        }
      ],
      "source": [
        "# install required dependencies\n",
        "! pip install datasets google-cloud-aiplatform openai pandas tiktoken langchain cassio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "222f44ff",
      "metadata": {
        "id": "222f44ff"
      },
      "source": [
        "You may be asked to \"Restart the Runtime\" at this time, as some dependencies\n",
        "have been upgraded. **Please do restart the runtime now** for a smoother execution from this point onward."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Astra DB Setup**\n",
        "The following steps will ask for the keyspace of the vector search enabled Astra DB that you want to use for this example, as well as the Astra DB Token that you generated as part of the prerequisites. You will also require to upload the [Secure Connect Bundle](https://awesome-astra.github.io/docs/pages/astra/download-scb/#c-procedure).\n",
        "Lastly, we are going to create helper functions for a secure connection to Astra DB `getCQLSession` `getCQLKeyspace` and `getTableCount`"
      ],
      "metadata": {
        "id": "qSZ3-OG5Kdh6"
      },
      "id": "qSZ3-OG5Kdh6"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zh4P-XUDq4u9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc271b01-e683-4db9-c17e-58d98c55ae58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Astra DB Keyspace name: vector_preview\n"
          ]
        }
      ],
      "source": [
        "# Input your database keyspace name:\n",
        "ASTRA_DB_KEYSPACE = input('Your Astra DB Keyspace name: ')"
      ],
      "id": "zh4P-XUDq4u9"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lThGqYchq4u-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3013efed-cba5-4660-b586-771b66572c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your Astra DB Token: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "# Input your Astra DB token string, the one starting with \"AstraCS:...\"\n",
        "ASTRA_DB_TOKEN_BASED_PASSWORD = getpass('Your Astra DB Token: ')"
      ],
      "id": "lThGqYchq4u-"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xnNziXZ1q4vD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "06a676ba-d3f9-44d4-ae6e-268a932b67ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your Secure Connect Bundle\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2ec103a2-925e-47df-9889-e34422ade7e0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2ec103a2-925e-47df-9889-e34422ade7e0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving secure-connect-osaeed-vector.zip to secure-connect-osaeed-vector.zip\n"
          ]
        }
      ],
      "source": [
        "# Upload your Secure Connect Bundle zipfile:\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "print('Please upload your Secure Connect Bundle')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    astraBundleFileTitle = list(uploaded.keys())[0]\n",
        "    ASTRA_DB_SECURE_BUNDLE_PATH = os.path.join(os.getcwd(), astraBundleFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Secure Connect Bundle. Please re-run the cell.'\n",
        "    )"
      ],
      "id": "xnNziXZ1q4vD"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TUDw-07Iq4vE"
      },
      "outputs": [],
      "source": [
        "# colab-specific override of helper functions\n",
        "from cassandra.cluster import (\n",
        "    Cluster,\n",
        ")\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "\n",
        "# The \"username\" is the literal string 'token' for this connection mode:\n",
        "ASTRA_DB_TOKEN_BASED_USERNAME = 'token'\n",
        "\n",
        "\n",
        "def getCQLSession(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        cluster = Cluster(\n",
        "            cloud={\n",
        "                \"secure_connect_bundle\": ASTRA_DB_SECURE_BUNDLE_PATH,\n",
        "            },\n",
        "            auth_provider=PlainTextAuthProvider(\n",
        "                ASTRA_DB_TOKEN_BASED_USERNAME,\n",
        "                ASTRA_DB_TOKEN_BASED_PASSWORD,\n",
        "            ),\n",
        "        )\n",
        "        astraSession = cluster.connect()\n",
        "        return astraSession\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')\n",
        "\n",
        "def getCQLKeyspace(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        return ASTRA_DB_KEYSPACE\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')\n",
        "\n",
        "def getTableCount():\n",
        "  # create a query that counts the number of records of the Astra DB table\n",
        "  query = SimpleStatement(f\"\"\"SELECT COUNT(*) FROM {keyspace}.{table_name};\"\"\")\n",
        "\n",
        "  # execute the query\n",
        "  results = session.execute(query)\n",
        "  return results.one().count\n"
      ],
      "id": "TUDw-07Iq4vE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXCQ6T_Gjk0Oz"
      },
      "source": [
        "## **LLM Provider**\n",
        "\n",
        "In the cell below you can choose between **GCP VertexAI** or **OpenAI** for your LLM services.\n",
        "(See [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org for more details).\n",
        "\n",
        "Make sure you set the `llmProvider` variable and supply the corresponding access secrets in the following cell."
      ],
      "id": "QXCQ6T_Gjk0Oz"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pGpzZc5zq4vG"
      },
      "outputs": [],
      "source": [
        "# Set your secret(s) for LLM access:\n",
        "llmProvider = 'OpenAI'  # 'GCP_VertexAI'\n"
      ],
      "id": "pGpzZc5zq4vG"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zOFStlEAq4vH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8521ca2-c45d-4201-fd57-396d0893899b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your secret for LLM provider \"OpenAI\": ··········\n"
          ]
        }
      ],
      "source": [
        "if llmProvider == 'OpenAI':\n",
        "    apiSecret = getpass(f'Your secret for LLM provider \"{llmProvider}\": ')\n",
        "    os.environ['OPENAI_API_KEY'] = apiSecret\n",
        "elif llmProvider == 'GCP_VertexAI':\n",
        "    # we need a json file\n",
        "    print(f'Please upload your Service Account JSON for the LLM provider \"{llmProvider}\":')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        vertexAIJsonFileTitle = list(uploaded.keys())[0]\n",
        "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.join(os.getcwd(), vertexAIJsonFileTitle)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            'No file uploaded. Please re-run the cell.'\n",
        "        )\n",
        "else:\n",
        "    raise ValueError('Unknown/unsupported LLM Provider')"
      ],
      "id": "zOFStlEAq4vH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Setup**\n",
        "We will use the US Constitution as our dataset"
      ],
      "metadata": {
        "id": "6Xo9boKEeSwf"
      },
      "id": "6Xo9boKEeSwf"
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://www.govinfo.gov/content/pkg/CDOC-110hdoc50/html/CDOC-110hdoc50.htm > constitution.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O20WtRdvecvx",
        "outputId": "d51152ad-8e36-4c28-8389-d4e6fd48ab34"
      },
      "id": "O20WtRdvecvx",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  291k    0  291k    0     0   285k      0 --:--:--  0:00:01 --:--:--  285k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import (\n",
        "    CharacterTextSplitter,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "\n",
        "loader = TextLoader(\"constitution.txt\")\n",
        "\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrS7xcpUelzB",
        "outputId": "73a6e3fc-8bed-43b8-e4bf-37a6b5c0ca98"
      },
      "id": "NrS7xcpUelzB",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 4562, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 21641, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 6612, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2609, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2239, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1870, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2679, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1111, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1860, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2927, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2233, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2149, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1702, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1615, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1016, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1887, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2394, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2017, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1824, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1588, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1672, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1678, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1721, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2739, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1978, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1591, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1477, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1034, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1025, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 12487, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3409, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 28779, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 9344, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 8742, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2733, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1842, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 4688, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 9278, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 7108, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 5295, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 4497, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3035, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 5293, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 23409, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2916, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 13488, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 19609, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 9183, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1606, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 7562, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2578, which is longer than the specified 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our example, our \"meaningful\" primary keys will just be the rowid as a string.  We will determine how many chunks our input file has been chopped into, and then just create a string array of sequential integers."
      ],
      "metadata": {
        "id": "V8fIfN9itVG3"
      },
      "id": "V8fIfN9itVG3"
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bY_rnZ3Mfug",
        "outputId": "4932a7ce-1670-4376-d9a0-3529960cfa17"
      },
      "id": "_bY_rnZ3Mfug",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intids = list(range(len(docs)))\n",
        "stringids = [str(x) for x in intids]\n",
        "stringids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J-SK4zyNPJI",
        "outputId": "7bc73a3c-5a2d-4521-aec3-87d997463672"
      },
      "id": "2J-SK4zyNPJI",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " '10',\n",
              " '11',\n",
              " '12',\n",
              " '13',\n",
              " '14',\n",
              " '15',\n",
              " '16',\n",
              " '17',\n",
              " '18',\n",
              " '19',\n",
              " '20',\n",
              " '21',\n",
              " '22',\n",
              " '23',\n",
              " '24',\n",
              " '25',\n",
              " '26',\n",
              " '27',\n",
              " '28',\n",
              " '29',\n",
              " '30',\n",
              " '31',\n",
              " '32',\n",
              " '33',\n",
              " '34',\n",
              " '35',\n",
              " '36',\n",
              " '37',\n",
              " '38',\n",
              " '39',\n",
              " '40',\n",
              " '41',\n",
              " '42',\n",
              " '43',\n",
              " '44',\n",
              " '45',\n",
              " '46',\n",
              " '47',\n",
              " '48',\n",
              " '49',\n",
              " '50',\n",
              " '51',\n",
              " '52',\n",
              " '53',\n",
              " '54',\n",
              " '55',\n",
              " '56',\n",
              " '57',\n",
              " '58',\n",
              " '59',\n",
              " '60',\n",
              " '61',\n",
              " '62',\n",
              " '63',\n",
              " '64',\n",
              " '65',\n",
              " '66',\n",
              " '67',\n",
              " '68',\n",
              " '69',\n",
              " '70',\n",
              " '71',\n",
              " '72',\n",
              " '73',\n",
              " '74',\n",
              " '75',\n",
              " '76',\n",
              " '77',\n",
              " '78',\n",
              " '79',\n",
              " '80',\n",
              " '81',\n",
              " '82',\n",
              " '83',\n",
              " '84',\n",
              " '85',\n",
              " '86',\n",
              " '87',\n",
              " '88',\n",
              " '89',\n",
              " '90',\n",
              " '91',\n",
              " '92',\n",
              " '93',\n",
              " '94',\n",
              " '95',\n",
              " '96',\n",
              " '97',\n",
              " '98',\n",
              " '99',\n",
              " '100',\n",
              " '101',\n",
              " '102',\n",
              " '103',\n",
              " '104',\n",
              " '105',\n",
              " '106',\n",
              " '107',\n",
              " '108',\n",
              " '109',\n",
              " '110',\n",
              " '111',\n",
              " '112',\n",
              " '113',\n",
              " '114',\n",
              " '115',\n",
              " '116',\n",
              " '117',\n",
              " '118',\n",
              " '119',\n",
              " '120',\n",
              " '121',\n",
              " '122',\n",
              " '123',\n",
              " '124',\n",
              " '125',\n",
              " '126',\n",
              " '127']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6715bc2b",
      "metadata": {
        "id": "6715bc2b"
      },
      "source": [
        "### **Load into Astra DB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "11013224",
      "metadata": {
        "id": "11013224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025a2dc4-1688-452e-b502-de98b787de64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 8dce574d-98e5-4b4d-bdfe-2477340a5d09-us-east1.db.astra.datastax.com:29042:4826ba60-d274-4b3b-944f-51d42fe5ae61. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 8dce574d-98e5-4b4d-bdfe-2477340a5d09-us-east1.db.astra.datastax.com:29042:4826ba60-d274-4b3b-944f-51d42fe5ae61. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(134194936100608) 8dce574d-98e5-4b4d-bdfe-2477340a5d09-us-east1.db.astra.datastax.com:29042:4826ba60-d274-4b3b-944f-51d42fe5ae61> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 8dce574d-98e5-4b4d-bdfe-2477340a5d09-us-east1.db.astra.datastax.com:29042:4826ba60-d274-4b3b-944f-51d42fe5ae61. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "from cassandra.query import SimpleStatement\n",
        "\n",
        "# creation of the DB connection\n",
        "cqlMode = 'astra_db'\n",
        "session = getCQLSession(mode=cqlMode)\n",
        "keyspace = getCQLKeyspace(mode=cqlMode)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below I have pasted our modified version of langchain.vectorstores.Cassandra .  I have modified the from_docuemnts and from_text methods to accept a lsit of ids."
      ],
      "metadata": {
        "id": "0NuwIqoCtwkH"
      },
      "id": "0NuwIqoCtwkH"
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import typing\n",
        "import uuid\n",
        "from typing import (\n",
        "    Any,\n",
        "    Callable,\n",
        "    Dict,\n",
        "    Iterable,\n",
        "    List,\n",
        "    Optional,\n",
        "    Tuple,\n",
        "    Type,\n",
        "    TypeVar,\n",
        "    Union,\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from cassandra.cluster import Session\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.schema.embeddings import Embeddings\n",
        "from langchain.schema.vectorstore import VectorStore\n",
        "from langchain.vectorstores.utils import maximal_marginal_relevance\n",
        "\n",
        "CVST = TypeVar(\"CVST\", bound=\"Cassandra\")\n",
        "\n",
        "\n",
        "class Cassandra(VectorStore):\n",
        "    \"\"\"Wrapper around Apache Cassandra(R) for vector-store workloads.\n",
        "\n",
        "    To use it, you need a recent installation of the `cassio` library\n",
        "    and a Cassandra cluster / Astra DB instance supporting vector capabilities.\n",
        "\n",
        "    Visit the cassio.org website for extensive quickstarts and code examples.\n",
        "\n",
        "    Example:\n",
        "        .. code-block:: python\n",
        "\n",
        "                from langchain.vectorstores import Cassandra\n",
        "                from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "                embeddings = OpenAIEmbeddings()\n",
        "                session = ...             # create your Cassandra session object\n",
        "                keyspace = 'my_keyspace'  # the keyspace should exist already\n",
        "                table_name = 'my_vector_store'\n",
        "                vectorstore = Cassandra(embeddings, session, keyspace, table_name)\n",
        "    \"\"\"\n",
        "\n",
        "    _embedding_dimension: Union[int, None]\n",
        "\n",
        "    @staticmethod\n",
        "    def _filter_to_metadata(filter_dict: Optional[Dict[str, str]]) -> Dict[str, Any]:\n",
        "        if filter_dict is None:\n",
        "            return {}\n",
        "        else:\n",
        "            return filter_dict\n",
        "\n",
        "    def _get_embedding_dimension(self) -> int:\n",
        "        if self._embedding_dimension is None:\n",
        "            self._embedding_dimension = len(\n",
        "                self.embedding.embed_query(\"This is a sample sentence.\")\n",
        "            )\n",
        "        return self._embedding_dimension\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding: Embeddings,\n",
        "        session: Session,\n",
        "        keyspace: str,\n",
        "        table_name: str,\n",
        "        ttl_seconds: Optional[int] = None,\n",
        "    ) -> None:\n",
        "        try:\n",
        "            from cassio.vector import VectorTable\n",
        "        except (ImportError, ModuleNotFoundError):\n",
        "            raise ImportError(\n",
        "                \"Could not import cassio python package. \"\n",
        "                \"Please install it with `pip install cassio`.\"\n",
        "            )\n",
        "        \"\"\"Create a vector table.\"\"\"\n",
        "        self.embedding = embedding\n",
        "        self.session = session\n",
        "        self.keyspace = keyspace\n",
        "        self.table_name = table_name\n",
        "        self.ttl_seconds = ttl_seconds\n",
        "        #\n",
        "        self._embedding_dimension = None\n",
        "        #\n",
        "        self.table = VectorTable(\n",
        "            session=session,\n",
        "            keyspace=keyspace,\n",
        "            table=table_name,\n",
        "            embedding_dimension=self._get_embedding_dimension(),\n",
        "            primary_key_type=\"TEXT\",\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def embeddings(self) -> Embeddings:\n",
        "        return self.embedding\n",
        "\n",
        "    @staticmethod\n",
        "    def _dont_flip_the_cos_score(distance: float) -> float:\n",
        "        # the identity\n",
        "        return distance\n",
        "\n",
        "    def _select_relevance_score_fn(self) -> Callable[[float], float]:\n",
        "        \"\"\"\n",
        "        The underlying VectorTable already returns a \"score proper\",\n",
        "        i.e. one in [0, 1] where higher means more *similar*,\n",
        "        so here the final score transformation is not reversing the interval:\n",
        "        \"\"\"\n",
        "        return self._dont_flip_the_cos_score\n",
        "\n",
        "    def delete_collection(self) -> None:\n",
        "        \"\"\"\n",
        "        Just an alias for `clear`\n",
        "        (to better align with other VectorStore implementations).\n",
        "        \"\"\"\n",
        "        self.clear()\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        \"\"\"Empty the collection.\"\"\"\n",
        "        self.table.clear()\n",
        "\n",
        "    def delete_by_document_id(self, document_id: str) -> None:\n",
        "        return self.table.delete(document_id)\n",
        "\n",
        "    def delete(self, ids: Optional[List[str]] = None, **kwargs: Any) -> Optional[bool]:\n",
        "        \"\"\"Delete by vector IDs.\n",
        "\n",
        "\n",
        "        Args:\n",
        "            ids: List of ids to delete.\n",
        "\n",
        "        Returns:\n",
        "            Optional[bool]: True if deletion is successful,\n",
        "            False otherwise, None if not implemented.\n",
        "        \"\"\"\n",
        "\n",
        "        if ids is None:\n",
        "            raise ValueError(\"No ids provided to delete.\")\n",
        "\n",
        "        for document_id in ids:\n",
        "            self.delete_by_document_id(document_id)\n",
        "        return True\n",
        "\n",
        "    def add_texts(\n",
        "        self,\n",
        "        texts: Iterable[str],\n",
        "        metadatas: Optional[List[dict]] = None,\n",
        "        ids: Optional[List[str]] = None,\n",
        "        batch_size: int = 16,\n",
        "        ttl_seconds: Optional[int] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
        "\n",
        "        Args:\n",
        "            texts (Iterable[str]): Texts to add to the vectorstore.\n",
        "            metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
        "            ids (Optional[List[str]], optional): Optional list of IDs.\n",
        "            batch_size (int): Number of concurrent requests to send to the server.\n",
        "            ttl_seconds (Optional[int], optional): Optional time-to-live\n",
        "                for the added texts.\n",
        "\n",
        "        Returns:\n",
        "            List[str]: List of IDs of the added texts.\n",
        "        \"\"\"\n",
        "        _texts = list(texts)  # lest it be a generator or something\n",
        "        if ids is None:\n",
        "            ids = [uuid.uuid4().hex for _ in _texts]\n",
        "        if metadatas is None:\n",
        "            metadatas = [{} for _ in _texts]\n",
        "        #\n",
        "        ttl_seconds = ttl_seconds or self.ttl_seconds\n",
        "        #\n",
        "        embedding_vectors = self.embedding.embed_documents(_texts)\n",
        "        #\n",
        "        for i in range(0, len(_texts), batch_size):\n",
        "            batch_texts = _texts[i : i + batch_size]\n",
        "            batch_embedding_vectors = embedding_vectors[i : i + batch_size]\n",
        "            batch_ids = ids[i : i + batch_size]\n",
        "            batch_metadatas = metadatas[i : i + batch_size]\n",
        "\n",
        "            futures = [\n",
        "                self.table.put_async(\n",
        "                    text, embedding_vector, text_id, metadata, ttl_seconds\n",
        "                )\n",
        "                for text, embedding_vector, text_id, metadata in zip(\n",
        "                    batch_texts, batch_embedding_vectors, batch_ids, batch_metadatas\n",
        "                )\n",
        "            ]\n",
        "            for future in futures:\n",
        "                future.result()\n",
        "        return ids\n",
        "\n",
        "    # id-returning search facilities\n",
        "    def similarity_search_with_score_id_by_vector(\n",
        "        self,\n",
        "        embedding: List[float],\n",
        "        k: int = 4,\n",
        "        filter: Optional[Dict[str, str]] = None,\n",
        "    ) -> List[Tuple[Document, float, str]]:\n",
        "        \"\"\"Return docs most similar to embedding vector.\n",
        "\n",
        "        Args:\n",
        "            embedding (str): Embedding to look up documents similar to.\n",
        "            k (int): Number of Documents to return. Defaults to 4.\n",
        "        Returns:\n",
        "            List of (Document, score, id), the most similar to the query vector.\n",
        "        \"\"\"\n",
        "        search_metadata = self._filter_to_metadata(filter)\n",
        "        #\n",
        "        hits = self.table.search(\n",
        "            embedding_vector=embedding,\n",
        "            top_k=k,\n",
        "            metric=\"cos\",\n",
        "            metric_threshold=None,\n",
        "            metadata=search_metadata,\n",
        "        )\n",
        "        # We stick to 'cos' distance as it can be normalized on a 0-1 axis\n",
        "        # (1=most relevant), as required by this class' contract.\n",
        "        return [\n",
        "            (\n",
        "                Document(\n",
        "                    page_content=hit[\"document\"],\n",
        "                    metadata=hit[\"metadata\"],\n",
        "                ),\n",
        "                0.5 + 0.5 * hit[\"distance\"],\n",
        "                hit[\"document_id\"],\n",
        "            )\n",
        "            for hit in hits\n",
        "        ]\n",
        "\n",
        "    def similarity_search_with_score_id(\n",
        "        self,\n",
        "        query: str,\n",
        "        k: int = 4,\n",
        "        filter: Optional[Dict[str, str]] = None,\n",
        "    ) -> List[Tuple[Document, float, str]]:\n",
        "        embedding_vector = self.embedding.embed_query(query)\n",
        "        return self.similarity_search_with_score_id_by_vector(\n",
        "            embedding=embedding_vector,\n",
        "            k=k,\n",
        "            filter=filter,\n",
        "        )\n",
        "\n",
        "    # id-unaware search facilities\n",
        "    def similarity_search_with_score_by_vector(\n",
        "        self,\n",
        "        embedding: List[float],\n",
        "        k: int = 4,\n",
        "        filter: Optional[Dict[str, str]] = None,\n",
        "    ) -> List[Tuple[Document, float]]:\n",
        "        \"\"\"Return docs most similar to embedding vector.\n",
        "\n",
        "        Args:\n",
        "            embedding (str): Embedding to look up documents similar to.\n",
        "            k (int): Number of Documents to return. Defaults to 4.\n",
        "        Returns:\n",
        "            List of (Document, score), the most similar to the query vector.\n",
        "        \"\"\"\n",
        "        return [\n",
        "            (doc, score)\n",
        "            for (doc, score, docId) in self.similarity_search_with_score_id_by_vector(\n",
        "                embedding=embedding,\n",
        "                k=k,\n",
        "                filter=filter,\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    def similarity_search(\n",
        "        self,\n",
        "        query: str,\n",
        "        k: int = 4,\n",
        "        filter: Optional[Dict[str, str]] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> List[Document]:\n",
        "        embedding_vector = self.embedding.embed_query(query)\n",
        "        return self.similarity_search_by_vector(\n",
        "            embedding_vector,\n",
        "            k,\n",
        "            filter=filter,\n",
        "        )\n",
        "\n",
        "    def similarity_search_by_vector(\n",
        "        self,\n",
        "        embedding: List[float],\n",
        "        k: int = 4,\n",
        "        filter: Optional[Dict[str, str]] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> List[Document]:\n",
        "        return [\n",
        "            doc\n",
        "            for doc, _ in self.similarity_search_with_score_by_vector(\n",
        "                embedding,\n",
        "                k,\n",
        "                filter=filter,\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    def similarity_search_with_score(\n",
        "        self,\n",
        "        query: str,\n",
        "        k: int = 4,\n",
        "        filter: Optional[Dict[str, str]] = None,\n",
        "    ) -> List[Tuple[Document, float]]:\n",
        "        embedding_vector = self.embedding.embed_query(query)\n",
        "        return self.similarity_search_with_score_by_vector(\n",
        "            embedding_vector,\n",
        "            k,\n",
        "            filter=filter,\n",
        "        )\n",
        "\n",
        "    def max_marginal_relevance_search_by_vector(\n",
        "        self,\n",
        "        embedding: List[float],\n",
        "        k: int = 4,\n",
        "        fetch_k: int = 20,\n",
        "        lambda_mult: float = 0.5,\n",
        "        filter: Optional[Dict[str, str]] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> List[Document]:\n",
        "        \"\"\"Return docs selected using the maximal marginal relevance.\n",
        "        Maximal marginal relevance optimizes for similarity to query AND diversity\n",
        "        among selected documents.\n",
        "        Args:\n",
        "            embedding: Embedding to look up documents similar to.\n",
        "            k: Number of Documents to return.\n",
        "            fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
        "            lambda_mult: Number between 0 and 1 that determines the degree\n",
        "                        of diversity among the results with 0 corresponding\n",
        "                        to maximum diversity and 1 to minimum diversity.\n",
        "        Returns:\n",
        "            List of Documents selected by maximal marginal relevance.\n",
        "        \"\"\"\n",
        "        search_metadata = self._filter_to_metadata(filter)\n",
        "\n",
        "        prefetchHits = self.table.search(\n",
        "            embedding_vector=embedding,\n",
        "            top_k=fetch_k,\n",
        "            metric=\"cos\",\n",
        "            metric_threshold=None,\n",
        "            metadata=search_metadata,\n",
        "        )\n",
        "        # let the mmr utility pick the *indices* in the above array\n",
        "        mmrChosenIndices = maximal_marginal_relevance(\n",
        "            np.array(embedding, dtype=np.float32),\n",
        "            [pfHit[\"embedding_vector\"] for pfHit in prefetchHits],\n",
        "            k=k,\n",
        "            lambda_mult=lambda_mult,\n",
        "        )\n",
        "        mmrHits = [\n",
        "            pfHit\n",
        "            for pfIndex, pfHit in enumerate(prefetchHits)\n",
        "            if pfIndex in mmrChosenIndices\n",
        "        ]\n",
        "        return [\n",
        "            Document(\n",
        "                page_content=hit[\"document\"],\n",
        "                metadata=hit[\"metadata\"],\n",
        "            )\n",
        "            for hit in mmrHits\n",
        "        ]\n",
        "\n",
        "    def max_marginal_relevance_search(\n",
        "        self,\n",
        "        query: str,\n",
        "        k: int = 4,\n",
        "        fetch_k: int = 20,\n",
        "        lambda_mult: float = 0.5,\n",
        "        filter: Optional[Dict[str, str]] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> List[Document]:\n",
        "        \"\"\"Return docs selected using the maximal marginal relevance.\n",
        "        Maximal marginal relevance optimizes for similarity to query AND diversity\n",
        "        among selected documents.\n",
        "        Args:\n",
        "            query: Text to look up documents similar to.\n",
        "            k: Number of Documents to return.\n",
        "            fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
        "            lambda_mult: Number between 0 and 1 that determines the degree\n",
        "                        of diversity among the results with 0 corresponding\n",
        "                        to maximum diversity and 1 to minimum diversity.\n",
        "                        Optional.\n",
        "        Returns:\n",
        "            List of Documents selected by maximal marginal relevance.\n",
        "        \"\"\"\n",
        "        embedding_vector = self.embedding.embed_query(query)\n",
        "        return self.max_marginal_relevance_search_by_vector(\n",
        "            embedding_vector,\n",
        "            k,\n",
        "            fetch_k,\n",
        "            lambda_mult=lambda_mult,\n",
        "            filter=filter,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def from_texts(\n",
        "        cls: Type[CVST],\n",
        "        texts: List[str],\n",
        "        embedding: Embeddings,\n",
        "        metadatas: Optional[List[dict]] = None,\n",
        "        batch_size: int = 16,\n",
        "        ids: Optional[List[str]] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> CVST:\n",
        "        \"\"\"Create a Cassandra vectorstore from raw texts.\n",
        "\n",
        "        Originally No support for specifying text IDs, but we have changed to support ids asn an optional param\n",
        "\n",
        "        Returns:\n",
        "            a Cassandra vectorstore.\n",
        "        \"\"\"\n",
        "        session: Session = kwargs[\"session\"]\n",
        "        keyspace: str = kwargs[\"keyspace\"]\n",
        "        table_name: str = kwargs[\"table_name\"]\n",
        "        cassandraStore = cls(\n",
        "            embedding=embedding,\n",
        "            session=session,\n",
        "            keyspace=keyspace,\n",
        "            table_name=table_name,\n",
        "        )\n",
        "        cassandraStore.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
        "        return cassandraStore\n",
        "\n",
        "    @classmethod\n",
        "    def from_documents(\n",
        "        cls: Type[CVST],\n",
        "        documents: List[Document],\n",
        "        embedding: Embeddings,\n",
        "        batch_size: int = 16,\n",
        "        ids: Optional[List[str]] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> CVST:\n",
        "        \"\"\"Create a Cassandra vectorstore from a document list.\n",
        "\n",
        "        Originally No support for specifying text IDs, but we have changed to support ids asn an optional param\n",
        "\n",
        "        Returns:\n",
        "            a Cassandra vectorstore.\n",
        "        \"\"\"\n",
        "        texts = [doc.page_content for doc in documents]\n",
        "        metadatas = [doc.metadata for doc in documents]\n",
        "        session: Session = kwargs[\"session\"]\n",
        "        keyspace: str = kwargs[\"keyspace\"]\n",
        "        table_name: str = kwargs[\"table_name\"]\n",
        "        return cls.from_texts(\n",
        "            texts=texts,\n",
        "            metadatas=metadatas,\n",
        "            embedding=embedding,\n",
        "            session=session,\n",
        "            keyspace=keyspace,\n",
        "            table_name=table_name,\n",
        "            ids=ids\n",
        "        )"
      ],
      "metadata": {
        "id": "WyHjOsumVfca"
      },
      "id": "WyHjOsumVfca",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we insert into a table langchain_constitution1 without the ids specicified.  We will see that the ids are UUIDs."
      ],
      "metadata": {
        "id": "zgVfCF-Juu_8"
      },
      "id": "zgVfCF-Juu_8"
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_function = OpenAIEmbeddings()\n",
        "\n",
        "# use LangChain's Cassandra integration to load the chunked documents into Astra\n",
        "docsearch = Cassandra.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embeddings_function,\n",
        "    session=session,\n",
        "    keyspace=keyspace,\n",
        "    table_name='langchain_constitution1',\n",
        ")"
      ],
      "metadata": {
        "id": "hjtRBdrUjI-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f80ba6-0f45-4acd-dd9c-bf95079da8bc"
      },
      "id": "hjtRBdrUjI-w",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-67140f01988a>:92: DeprecationWarning: Class `VectorTable` is a legacy construct and will be deprecated in future versions of CassIO.\n",
            "  self.table = VectorTable(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "rows = session.execute(f\"\"\"select row_id, body_blob from vector_preview.langchain_constitution1 limit 5\"\"\")\n",
        "\n",
        "results = pd.DataFrame(rows)\n",
        "results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5H-WREKWwMBY",
        "outputId": "875deb63-6b33-4272-e4c9-3691016c69ba"
      },
      "id": "5H-WREKWwMBY",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             row_id  \\\n",
              "0  87c11bff6342478496ad348910f2620a   \n",
              "1  d7cd79c488ba4570a5605a0ef5748344   \n",
              "2  a5d54d0251a64ca9944f95da9d3909a4   \n",
              "3  359c562a5b95455687ae8e6f819e5435   \n",
              "4  7f2bc784c32e4f4eb6a6f6e94b25b2b2   \n",
              "\n",
              "                                           body_blob  \n",
              "0  During the course of our history, in addition ...  \n",
              "1                          Proposal and Ratification  \n",
              "2                          Proposal and Ratification  \n",
              "3  Geo: Read\\n                                   ...  \n",
              "4  Historical Note..................................  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fcd6634-ee8f-47bd-a728-f57f4c2c33d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>body_blob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87c11bff6342478496ad348910f2620a</td>\n",
              "      <td>During the course of our history, in addition ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d7cd79c488ba4570a5605a0ef5748344</td>\n",
              "      <td>Proposal and Ratification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a5d54d0251a64ca9944f95da9d3909a4</td>\n",
              "      <td>Proposal and Ratification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>359c562a5b95455687ae8e6f819e5435</td>\n",
              "      <td>Geo: Read\\n                                   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7f2bc784c32e4f4eb6a6f6e94b25b2b2</td>\n",
              "      <td>Historical Note..................................</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fcd6634-ee8f-47bd-a728-f57f4c2c33d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fcd6634-ee8f-47bd-a728-f57f4c2c33d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fcd6634-ee8f-47bd-a728-f57f4c2c33d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d11fe094-132c-4be3-97fe-76e69b1a4d24\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d11fe094-132c-4be3-97fe-76e69b1a4d24')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d11fe094-132c-4be3-97fe-76e69b1a4d24 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will insert into a table langchain_constitution2 with the ids specified.  We will see that the ids are integers."
      ],
      "metadata": {
        "id": "kY7bW_OjvCh3"
      },
      "id": "kY7bW_OjvCh3"
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_function = OpenAIEmbeddings()\n",
        "\n",
        "# use LangChain's Cassandra integration to load the chunked documents into Astra\n",
        "docsearch = Cassandra.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embeddings_function,\n",
        "    session=session,\n",
        "    keyspace=keyspace,\n",
        "    ids=stringids,\n",
        "    table_name='langchain_constitution2',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls7ixnPVvLOl",
        "outputId": "ae30866b-b0ed-4732-c973-e2c459d882f2"
      },
      "id": "ls7ixnPVvLOl",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-67140f01988a>:92: DeprecationWarning: Class `VectorTable` is a legacy construct and will be deprecated in future versions of CassIO.\n",
            "  self.table = VectorTable(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rows = session.execute(f\"\"\"select row_id, body_blob from vector_preview.langchain_constitution2 limit 5\"\"\")\n",
        "\n",
        "results = pd.DataFrame(rows)\n",
        "results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l4zCQFgiy0VQ",
        "outputId": "2ceb805c-ae43-4f12-8323-67c16f70b489"
      },
      "id": "l4zCQFgiy0VQ",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  row_id                                          body_blob\n",
              "0      6                                        Article II.\n",
              "1     90  Dangers as will not admit of delay. No        ...\n",
              "2     46                                      Article [XX.]\n",
              "3    115                                                  R\n",
              "4     55  This amendment was proposed to the legislature..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-524f5406-f005-4c4e-b84d-e87a4f119f7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>body_blob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>Article II.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90</td>\n",
              "      <td>Dangers as will not admit of delay. No        ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46</td>\n",
              "      <td>Article [XX.]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55</td>\n",
              "      <td>This amendment was proposed to the legislature...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-524f5406-f005-4c4e-b84d-e87a4f119f7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-524f5406-f005-4c4e-b84d-e87a4f119f7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-524f5406-f005-4c4e-b84d-e87a4f119f7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-518bea3a-449c-487f-afcf-b9d5d10399e3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-518bea3a-449c-487f-afcf-b9d5d10399e3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-518bea3a-449c-487f-afcf-b9d5d10399e3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}